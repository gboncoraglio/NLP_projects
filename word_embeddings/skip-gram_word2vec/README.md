Word2vec is a group of related models that are used to produce word embeddings.

Implementing Skip-gram word2vec model training with stochastic gradient
descent (SGD) on the Stanford Sentiment Treebank (SST) dataset.
The dimension of the word embedding is 10.

At the end of the training some word embeddings are visualized in a 2D space using
SVD for dimensionality reduction.
