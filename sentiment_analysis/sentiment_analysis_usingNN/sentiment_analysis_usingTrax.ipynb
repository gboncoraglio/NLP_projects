{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM2WI45DjCVp"
   },
   "source": [
    "#  Sentiment with Deep Neural Networks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOK4n9JEjCVs"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "#  Import libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "WOTfm2P0jCVt",
    "outputId": "d4903011-7268-4bea-ae35-ea3fd0b46311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbonco/anaconda3/lib/python3.7/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/gbonco/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gbonco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import random as rnd\n",
    "\n",
    "# import relevant libraries\n",
    "import trax\n",
    "\n",
    "# set random seeds to make this notebook easier to replicate\n",
    "trax.supervised.trainer_lib.init_random_number_generators(31)\n",
    "\n",
    "# import trax.fastmath.numpy\n",
    "import trax.fastmath.numpy as np\n",
    "\n",
    "# import trax.layers\n",
    "from trax import layers as tl\n",
    "\n",
    "# import Layer from the utils.py file\n",
    "from utils import Layer, load_tweets, process_tweet\n",
    "#from utils import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EyMnUt38jCVw",
    "outputId": "6981112a-3bf8-48a9-bf7d-6fc6d64150b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(5., dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jax.interpreters.xla.DeviceArray'>\n"
     ]
    }
   ],
   "source": [
    "# Create an array using trax.fastmath.numpy\n",
    "a = np.array(5.0)\n",
    "\n",
    "# View the returned array\n",
    "display(a)\n",
    "\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WtEWAFUIjCVz"
   },
   "source": [
    "Notice that trax.fastmath.numpy returns a DeviceArray from the jax library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2RUtDtrjCV0"
   },
   "outputs": [],
   "source": [
    "# Define a function that will use the trax.fastmath.numpy array\n",
    "def f(x):\n",
    "    \n",
    "    # f = x^2\n",
    "    return (x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qvUd-xzqjCV4",
    "outputId": "cdda13b4-b56b-4d10-e6be-abbfcb523e78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(a) for a=5.0 is 25.0\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "print(f\"f(a) for a={a} is {f(a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2Im5Hkc9jCV8",
    "outputId": "4c963756-9b0d-46b8-b05d-a8e4de5d0740"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly use trax.fastmath.grad to calculate the gradient (derivative) of the function\n",
    "grad_f = trax.fastmath.grad(fun=f)  # df / dx - Gradient of function f(x) with respect to x\n",
    "\n",
    "# View the type of the retuned object (it's a function)\n",
    "type(grad_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0lDIVvx3jCV_",
    "outputId": "16ad5e34-f634-4d38-ccd8-96786e1d412d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(10., dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the newly created function and pass in a value for x (the DeviceArray stored in 'a')\n",
    "grad_calculation = grad_f(a)\n",
    "\n",
    "# View the result of calling the grad_f function\n",
    "display(grad_calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41l3WDBkjCWD"
   },
   "source": [
    "The function returned by trax.fastmath.grad takes in x=5 and calculates the gradient of f, which is 2*x, which is 10. The value is also stored as a DeviceArray from the jax library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZ8RUynQsktn"
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "#  Importing the data\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "##   Loading in the data\n",
    "\n",
    "Import the data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "h5ClwIOSuLJh",
    "outputId": "dee50364-c476-405f-8cdd-63d067b848d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive tweets: 5000\n",
      "The number of negative tweets: 5000\n",
      "length of train_x 8000\n",
      "length of val_x 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import functions from the utils.py file\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load positive and negative tweets\n",
    "all_positive_tweets, all_negative_tweets = load_tweets()\n",
    "\n",
    "# View the total number of positive and negative tweets.\n",
    "print(f\"The number of positive tweets: {len(all_positive_tweets)}\")\n",
    "print(f\"The number of negative tweets: {len(all_negative_tweets)}\")\n",
    "\n",
    "# Split positive set into validation and training\n",
    "val_pos   = all_positive_tweets[4000:] # generating validation set for positive tweets\n",
    "train_pos  = all_positive_tweets[:4000]# generating training set for positive tweets\n",
    "\n",
    "# Split negative set into validation and training\n",
    "val_neg   = all_negative_tweets[4000:] # generating validation set for negative tweets\n",
    "train_neg  = all_negative_tweets[:4000] # generating training set for nagative tweets\n",
    "\n",
    "# Combine training data into one set\n",
    "train_x = train_pos + train_neg \n",
    "\n",
    "# Combine validation data into one set\n",
    "val_x  = val_pos + val_neg\n",
    "\n",
    "# Set the labels for the training set (1 for positive, 0 for negative)\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "\n",
    "# Set the labels for the validation set (1 for positive, 0 for negative)\n",
    "val_y  = np.append(np.ones(len(val_pos)), np.zeros(len(val_neg)))\n",
    "\n",
    "print(f\"length of train_x {len(train_x)}\")\n",
    "print(f\"length of val_x {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNQq4LmbjCWG"
   },
   "source": [
    "Now import a function that processes tweets \n",
    "- `process_tweets' removes unwanted characters e.g. hashtag, hyperlinks, stock tickers from tweet.\n",
    "- It also returns a list of words (it tokenizes the original string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "2bRX6aPDjCWH",
    "outputId": "09497362-bf73-4d63-e99f-460027e91eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tweet at training position 0\n",
      "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "Tweet at training position 0 after processing:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a function that processes the tweets\n",
    "# from utils import process_tweet\n",
    "\n",
    "# Try out function that processes tweets\n",
    "print(\"original tweet at training position 0\")\n",
    "print(train_pos[0])\n",
    "\n",
    "print(\"Tweet at training position 0 after processing:\")\n",
    "process_tweet(train_pos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00XdS3LOjCWK"
   },
   "source": [
    "Notice that the function `process_tweet` keeps key words, removes the hash # symbol, and ignores usernames (words that begin with '@').  It also returns a list of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ac4D5WSUAVub"
   },
   "source": [
    "<a name=\"2.2\"></a>\n",
    "## 2.2  Building the vocabulary\n",
    "\n",
    "Now build the vocabulary.\n",
    "- Map each word in each tweet to an integer (an \"index\"). \n",
    "- The following code does this for you, but please read it and understand what it's doing.\n",
    "- Note that you will build the vocabulary based on the training data. \n",
    "- To do so, you will assign an index to everyword by iterating over your training set.\n",
    "\n",
    "The vocabulary will also include some special tokens\n",
    "- `__PAD__`: padding\n",
    "- `</e>`: end of line\n",
    "- `__UNK__`: a token representing any word that is not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rQaHKs7kAVuc",
    "outputId": "1d360f94-902d-471c-d3c3-0d69c27f5eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 9092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__PAD__': 0,\n",
       " '__</e>__': 1,\n",
       " '__UNK__': 2,\n",
       " 'followfriday': 3,\n",
       " 'top': 4,\n",
       " 'engag': 5,\n",
       " 'member': 6,\n",
       " 'commun': 7,\n",
       " 'week': 8,\n",
       " ':)': 9,\n",
       " 'hey': 10,\n",
       " 'jame': 11,\n",
       " 'odd': 12,\n",
       " ':/': 13,\n",
       " 'pleas': 14,\n",
       " 'call': 15,\n",
       " 'contact': 16,\n",
       " 'centr': 17,\n",
       " '02392441234': 18,\n",
       " 'abl': 19,\n",
       " 'assist': 20,\n",
       " 'mani': 21,\n",
       " 'thank': 22,\n",
       " 'listen': 23,\n",
       " 'last': 24,\n",
       " 'night': 25,\n",
       " 'bleed': 26,\n",
       " 'amaz': 27,\n",
       " 'track': 28,\n",
       " 'scotland': 29,\n",
       " 'congrat': 30,\n",
       " 'yeaaah': 31,\n",
       " 'yipppi': 32,\n",
       " 'accnt': 33,\n",
       " 'verifi': 34,\n",
       " 'rqst': 35,\n",
       " 'succeed': 36,\n",
       " 'got': 37,\n",
       " 'blue': 38,\n",
       " 'tick': 39,\n",
       " 'mark': 40,\n",
       " 'fb': 41,\n",
       " 'profil': 42,\n",
       " '15': 43,\n",
       " 'day': 44,\n",
       " 'one': 45,\n",
       " 'irresist': 46,\n",
       " 'flipkartfashionfriday': 47,\n",
       " 'like': 48,\n",
       " 'keep': 49,\n",
       " 'love': 50,\n",
       " 'custom': 51,\n",
       " 'wait': 52,\n",
       " 'long': 53,\n",
       " 'hope': 54,\n",
       " 'enjoy': 55,\n",
       " 'happi': 56,\n",
       " 'friday': 57,\n",
       " 'lwwf': 58,\n",
       " 'second': 59,\n",
       " 'thought': 60,\n",
       " '’': 61,\n",
       " 'enough': 62,\n",
       " 'time': 63,\n",
       " 'dd': 64,\n",
       " 'new': 65,\n",
       " 'short': 66,\n",
       " 'enter': 67,\n",
       " 'system': 68,\n",
       " 'sheep': 69,\n",
       " 'must': 70,\n",
       " 'buy': 71,\n",
       " 'jgh': 72,\n",
       " 'go': 73,\n",
       " 'bayan': 74,\n",
       " ':D': 75,\n",
       " 'bye': 76,\n",
       " 'act': 77,\n",
       " 'mischiev': 78,\n",
       " 'etl': 79,\n",
       " 'layer': 80,\n",
       " 'in-hous': 81,\n",
       " 'wareh': 82,\n",
       " 'app': 83,\n",
       " 'katamari': 84,\n",
       " 'well': 85,\n",
       " '…': 86,\n",
       " 'name': 87,\n",
       " 'impli': 88,\n",
       " ':p': 89,\n",
       " 'influenc': 90,\n",
       " 'big': 91,\n",
       " '...': 92,\n",
       " 'juici': 93,\n",
       " 'selfi': 94,\n",
       " 'follow': 95,\n",
       " 'perfect': 96,\n",
       " 'alreadi': 97,\n",
       " 'know': 98,\n",
       " \"what'\": 99,\n",
       " 'great': 100,\n",
       " 'opportun': 101,\n",
       " 'junior': 102,\n",
       " 'triathlet': 103,\n",
       " 'age': 104,\n",
       " '12': 105,\n",
       " '13': 106,\n",
       " 'gatorad': 107,\n",
       " 'seri': 108,\n",
       " 'get': 109,\n",
       " 'entri': 110,\n",
       " 'lay': 111,\n",
       " 'greet': 112,\n",
       " 'card': 113,\n",
       " 'rang': 114,\n",
       " 'print': 115,\n",
       " 'today': 116,\n",
       " 'job': 117,\n",
       " ':-)': 118,\n",
       " \"friend'\": 119,\n",
       " 'lunch': 120,\n",
       " 'yummm': 121,\n",
       " 'nostalgia': 122,\n",
       " 'tb': 123,\n",
       " 'ku': 124,\n",
       " 'id': 125,\n",
       " 'conflict': 126,\n",
       " 'help': 127,\n",
       " \"here'\": 128,\n",
       " 'screenshot': 129,\n",
       " 'work': 130,\n",
       " 'hi': 131,\n",
       " 'liv': 132,\n",
       " 'hello': 133,\n",
       " 'need': 134,\n",
       " 'someth': 135,\n",
       " 'u': 136,\n",
       " 'fm': 137,\n",
       " 'twitter': 138,\n",
       " '—': 139,\n",
       " 'sure': 140,\n",
       " 'thing': 141,\n",
       " 'dm': 142,\n",
       " 'x': 143,\n",
       " \"i'v\": 144,\n",
       " 'heard': 145,\n",
       " 'four': 146,\n",
       " 'season': 147,\n",
       " 'pretti': 148,\n",
       " 'dope': 149,\n",
       " 'penthous': 150,\n",
       " 'obv': 151,\n",
       " 'gobigorgohom': 152,\n",
       " 'fun': 153,\n",
       " \"y'all\": 154,\n",
       " 'yeah': 155,\n",
       " 'suppos': 156,\n",
       " 'lol': 157,\n",
       " 'chat': 158,\n",
       " 'bit': 159,\n",
       " 'youth': 160,\n",
       " '💅': 161,\n",
       " '🏽': 162,\n",
       " '💋': 163,\n",
       " 'seen': 164,\n",
       " 'year': 165,\n",
       " 'rest': 166,\n",
       " 'goe': 167,\n",
       " 'quickli': 168,\n",
       " 'bed': 169,\n",
       " 'music': 170,\n",
       " 'fix': 171,\n",
       " 'dream': 172,\n",
       " 'spiritu': 173,\n",
       " 'ritual': 174,\n",
       " 'festiv': 175,\n",
       " 'népal': 176,\n",
       " 'begin': 177,\n",
       " 'line-up': 178,\n",
       " 'left': 179,\n",
       " 'see': 180,\n",
       " 'sarah': 181,\n",
       " 'send': 182,\n",
       " 'us': 183,\n",
       " 'email': 184,\n",
       " 'bitsy@bitdefender.com': 185,\n",
       " \"we'll\": 186,\n",
       " 'asap': 187,\n",
       " 'kik': 188,\n",
       " 'hatessuc': 189,\n",
       " '32429': 190,\n",
       " 'kikm': 191,\n",
       " 'lgbt': 192,\n",
       " 'tinder': 193,\n",
       " 'nsfw': 194,\n",
       " 'akua': 195,\n",
       " 'cumshot': 196,\n",
       " 'come': 197,\n",
       " 'hous': 198,\n",
       " 'nsn_supplement': 199,\n",
       " 'effect': 200,\n",
       " 'press': 201,\n",
       " 'releas': 202,\n",
       " 'distribut': 203,\n",
       " 'result': 204,\n",
       " 'link': 205,\n",
       " 'remov': 206,\n",
       " 'pressreleas': 207,\n",
       " 'newsdistribut': 208,\n",
       " 'bam': 209,\n",
       " 'bestfriend': 210,\n",
       " 'lot': 211,\n",
       " 'warsaw': 212,\n",
       " '<3': 213,\n",
       " 'x46': 214,\n",
       " 'everyon': 215,\n",
       " 'watch': 216,\n",
       " 'documentari': 217,\n",
       " 'earthl': 218,\n",
       " 'youtub': 219,\n",
       " 'support': 220,\n",
       " 'buuut': 221,\n",
       " 'oh': 222,\n",
       " 'look': 223,\n",
       " 'forward': 224,\n",
       " 'visit': 225,\n",
       " 'next': 226,\n",
       " 'letsgetmessi': 227,\n",
       " 'jo': 228,\n",
       " 'make': 229,\n",
       " 'feel': 230,\n",
       " 'better': 231,\n",
       " 'never': 232,\n",
       " 'anyon': 233,\n",
       " 'kpop': 234,\n",
       " 'flesh': 235,\n",
       " 'good': 236,\n",
       " 'girl': 237,\n",
       " 'best': 238,\n",
       " 'wish': 239,\n",
       " 'reason': 240,\n",
       " 'epic': 241,\n",
       " 'soundtrack': 242,\n",
       " 'shout': 243,\n",
       " 'ad': 244,\n",
       " 'video': 245,\n",
       " 'playlist': 246,\n",
       " 'would': 247,\n",
       " 'dear': 248,\n",
       " 'jordan': 249,\n",
       " 'okay': 250,\n",
       " 'fake': 251,\n",
       " 'gameplay': 252,\n",
       " ';)': 253,\n",
       " 'haha': 254,\n",
       " 'im': 255,\n",
       " 'kid': 256,\n",
       " 'stuff': 257,\n",
       " 'exactli': 258,\n",
       " 'product': 259,\n",
       " 'line': 260,\n",
       " 'etsi': 261,\n",
       " 'shop': 262,\n",
       " 'check': 263,\n",
       " 'vacat': 264,\n",
       " 'recharg': 265,\n",
       " 'normal': 266,\n",
       " 'charger': 267,\n",
       " 'asleep': 268,\n",
       " 'talk': 269,\n",
       " 'sooo': 270,\n",
       " 'someon': 271,\n",
       " 'text': 272,\n",
       " 'ye': 273,\n",
       " 'bet': 274,\n",
       " \"he'll\": 275,\n",
       " 'fit': 276,\n",
       " 'hear': 277,\n",
       " 'speech': 278,\n",
       " 'piti': 279,\n",
       " 'green': 280,\n",
       " 'garden': 281,\n",
       " 'midnight': 282,\n",
       " 'sun': 283,\n",
       " 'beauti': 284,\n",
       " 'canal': 285,\n",
       " 'dasvidaniya': 286,\n",
       " 'till': 287,\n",
       " 'scout': 288,\n",
       " 'sg': 289,\n",
       " 'futur': 290,\n",
       " 'wlan': 291,\n",
       " 'pro': 292,\n",
       " 'confer': 293,\n",
       " 'asia': 294,\n",
       " 'chang': 295,\n",
       " 'lollipop': 296,\n",
       " '🍭': 297,\n",
       " 'nez': 298,\n",
       " 'agnezmo': 299,\n",
       " 'oley': 300,\n",
       " 'mama': 301,\n",
       " 'stand': 302,\n",
       " 'stronger': 303,\n",
       " 'god': 304,\n",
       " 'misti': 305,\n",
       " 'babi': 306,\n",
       " 'cute': 307,\n",
       " 'woohoo': 308,\n",
       " \"can't\": 309,\n",
       " 'sign': 310,\n",
       " 'yet': 311,\n",
       " 'still': 312,\n",
       " 'think': 313,\n",
       " 'mka': 314,\n",
       " 'liam': 315,\n",
       " 'access': 316,\n",
       " 'welcom': 317,\n",
       " 'stat': 318,\n",
       " 'arriv': 319,\n",
       " '1': 320,\n",
       " 'unfollow': 321,\n",
       " 'via': 322,\n",
       " 'surpris': 323,\n",
       " 'figur': 324,\n",
       " 'happybirthdayemilybett': 325,\n",
       " 'sweet': 326,\n",
       " 'talent': 327,\n",
       " '2': 328,\n",
       " 'plan': 329,\n",
       " 'drain': 330,\n",
       " 'gotta': 331,\n",
       " 'timezon': 332,\n",
       " 'parent': 333,\n",
       " 'proud': 334,\n",
       " 'least': 335,\n",
       " 'mayb': 336,\n",
       " 'sometim': 337,\n",
       " 'grade': 338,\n",
       " 'al': 339,\n",
       " 'grand': 340,\n",
       " 'manila_bro': 341,\n",
       " 'chosen': 342,\n",
       " 'let': 343,\n",
       " 'around': 344,\n",
       " '..': 345,\n",
       " 'side': 346,\n",
       " 'world': 347,\n",
       " 'eh': 348,\n",
       " 'take': 349,\n",
       " 'care': 350,\n",
       " 'final': 351,\n",
       " 'fuck': 352,\n",
       " 'weekend': 353,\n",
       " 'real': 354,\n",
       " 'x45': 355,\n",
       " 'join': 356,\n",
       " 'hushedcallwithfraydo': 357,\n",
       " 'gift': 358,\n",
       " 'yeahhh': 359,\n",
       " 'hushedpinwithsammi': 360,\n",
       " 'event': 361,\n",
       " 'might': 362,\n",
       " 'luv': 363,\n",
       " 'realli': 364,\n",
       " 'appreci': 365,\n",
       " 'share': 366,\n",
       " 'wow': 367,\n",
       " 'tom': 368,\n",
       " 'gym': 369,\n",
       " 'monday': 370,\n",
       " 'invit': 371,\n",
       " 'scope': 372,\n",
       " 'friend': 373,\n",
       " 'nude': 374,\n",
       " 'sleep': 375,\n",
       " 'birthday': 376,\n",
       " 'want': 377,\n",
       " 't-shirt': 378,\n",
       " 'cool': 379,\n",
       " 'haw': 380,\n",
       " 'phela': 381,\n",
       " 'mom': 382,\n",
       " 'obvious': 383,\n",
       " 'princ': 384,\n",
       " 'charm': 385,\n",
       " 'stage': 386,\n",
       " 'luck': 387,\n",
       " 'tyler': 388,\n",
       " 'hipster': 389,\n",
       " 'glass': 390,\n",
       " 'marti': 391,\n",
       " 'glad': 392,\n",
       " 'done': 393,\n",
       " 'afternoon': 394,\n",
       " 'read': 395,\n",
       " 'kahfi': 396,\n",
       " 'finish': 397,\n",
       " 'ohmyg': 398,\n",
       " 'yaya': 399,\n",
       " 'dub': 400,\n",
       " 'stalk': 401,\n",
       " 'ig': 402,\n",
       " 'gondooo': 403,\n",
       " 'moo': 404,\n",
       " 'tologooo': 405,\n",
       " 'becom': 406,\n",
       " 'detail': 407,\n",
       " 'zzz': 408,\n",
       " 'xx': 409,\n",
       " 'physiotherapi': 410,\n",
       " 'hashtag': 411,\n",
       " '💪': 412,\n",
       " 'monica': 413,\n",
       " 'miss': 414,\n",
       " 'sound': 415,\n",
       " 'morn': 416,\n",
       " \"that'\": 417,\n",
       " 'x43': 418,\n",
       " 'definit': 419,\n",
       " 'tri': 420,\n",
       " 'tonight': 421,\n",
       " 'took': 422,\n",
       " 'advic': 423,\n",
       " 'treviso': 424,\n",
       " 'concert': 425,\n",
       " 'citi': 426,\n",
       " 'countri': 427,\n",
       " \"i'll\": 428,\n",
       " 'start': 429,\n",
       " 'fine': 430,\n",
       " 'gorgeou': 431,\n",
       " 'xo': 432,\n",
       " 'oven': 433,\n",
       " 'roast': 434,\n",
       " 'garlic': 435,\n",
       " 'oliv': 436,\n",
       " 'oil': 437,\n",
       " 'dri': 438,\n",
       " 'tomato': 439,\n",
       " 'basil': 440,\n",
       " 'centuri': 441,\n",
       " 'tuna': 442,\n",
       " 'right': 443,\n",
       " 'back': 444,\n",
       " 'atchya': 445,\n",
       " 'even': 446,\n",
       " 'almost': 447,\n",
       " 'chanc': 448,\n",
       " 'cheer': 449,\n",
       " 'po': 450,\n",
       " 'ice': 451,\n",
       " 'cream': 452,\n",
       " 'agre': 453,\n",
       " '100': 454,\n",
       " 'heheheh': 455,\n",
       " 'that': 456,\n",
       " 'point': 457,\n",
       " 'stay': 458,\n",
       " 'home': 459,\n",
       " 'soon': 460,\n",
       " 'promis': 461,\n",
       " 'web': 462,\n",
       " 'whatsapp': 463,\n",
       " 'volta': 464,\n",
       " 'funcionar': 465,\n",
       " 'com': 466,\n",
       " 'iphon': 467,\n",
       " 'jailbroken': 468,\n",
       " 'later': 469,\n",
       " '34': 470,\n",
       " 'min': 471,\n",
       " 'leia': 472,\n",
       " 'appear': 473,\n",
       " 'hologram': 474,\n",
       " 'r2d2': 475,\n",
       " 'w': 476,\n",
       " 'messag': 477,\n",
       " 'obi': 478,\n",
       " 'wan': 479,\n",
       " 'sit': 480,\n",
       " 'luke': 481,\n",
       " 'inter': 482,\n",
       " '3': 483,\n",
       " 'ucl': 484,\n",
       " 'arsen': 485,\n",
       " 'small': 486,\n",
       " 'team': 487,\n",
       " 'pass': 488,\n",
       " '🚂': 489,\n",
       " 'dewsburi': 490,\n",
       " 'railway': 491,\n",
       " 'station': 492,\n",
       " 'dew': 493,\n",
       " 'west': 494,\n",
       " 'yorkshir': 495,\n",
       " '430': 496,\n",
       " 'smh': 497,\n",
       " '9:25': 498,\n",
       " 'live': 499,\n",
       " 'strang': 500,\n",
       " 'imagin': 501,\n",
       " 'megan': 502,\n",
       " 'masaantoday': 503,\n",
       " 'a4': 504,\n",
       " 'shweta': 505,\n",
       " 'tripathi': 506,\n",
       " '5': 507,\n",
       " '20': 508,\n",
       " 'kurta': 509,\n",
       " 'half': 510,\n",
       " 'number': 511,\n",
       " 'wsalelov': 512,\n",
       " 'ah': 513,\n",
       " 'larri': 514,\n",
       " 'anyway': 515,\n",
       " 'kinda': 516,\n",
       " 'goood': 517,\n",
       " 'life': 518,\n",
       " 'enn': 519,\n",
       " 'could': 520,\n",
       " 'warmup': 521,\n",
       " '15th': 522,\n",
       " 'bath': 523,\n",
       " 'dum': 524,\n",
       " 'andar': 525,\n",
       " 'ram': 526,\n",
       " 'sampath': 527,\n",
       " 'sona': 528,\n",
       " 'mohapatra': 529,\n",
       " 'samantha': 530,\n",
       " 'edward': 531,\n",
       " 'mein': 532,\n",
       " 'tulan': 533,\n",
       " 'razi': 534,\n",
       " 'wah': 535,\n",
       " 'josh': 536,\n",
       " 'alway': 537,\n",
       " 'smile': 538,\n",
       " 'pictur': 539,\n",
       " '16.20': 540,\n",
       " 'giveitup': 541,\n",
       " 'given': 542,\n",
       " 'ga': 543,\n",
       " 'subsidi': 544,\n",
       " 'initi': 545,\n",
       " 'propos': 546,\n",
       " 'delight': 547,\n",
       " 'yesterday': 548,\n",
       " 'x42': 549,\n",
       " 'lmaoo': 550,\n",
       " 'song': 551,\n",
       " 'ever': 552,\n",
       " 'shall': 553,\n",
       " 'littl': 554,\n",
       " 'throwback': 555,\n",
       " 'outli': 556,\n",
       " 'island': 557,\n",
       " 'cheung': 558,\n",
       " 'chau': 559,\n",
       " 'mui': 560,\n",
       " 'wo': 561,\n",
       " 'total': 562,\n",
       " 'differ': 563,\n",
       " 'kfckitchentour': 564,\n",
       " 'kitchen': 565,\n",
       " 'clean': 566,\n",
       " \"i'm\": 567,\n",
       " 'cusp': 568,\n",
       " 'test': 569,\n",
       " 'water': 570,\n",
       " 'reward': 571,\n",
       " 'arummzz': 572,\n",
       " \"let'\": 573,\n",
       " 'drive': 574,\n",
       " 'travel': 575,\n",
       " 'yogyakarta': 576,\n",
       " 'jeep': 577,\n",
       " 'indonesia': 578,\n",
       " 'instamood': 579,\n",
       " 'wanna': 580,\n",
       " 'skype': 581,\n",
       " 'may': 582,\n",
       " 'nice': 583,\n",
       " 'friendli': 584,\n",
       " 'pretend': 585,\n",
       " 'film': 586,\n",
       " 'congratul': 587,\n",
       " 'winner': 588,\n",
       " 'cheesydelight': 589,\n",
       " 'contest': 590,\n",
       " 'address': 591,\n",
       " 'guy': 592,\n",
       " 'market': 593,\n",
       " '24/7': 594,\n",
       " '14': 595,\n",
       " 'hour': 596,\n",
       " 'leav': 597,\n",
       " 'without': 598,\n",
       " 'delay': 599,\n",
       " 'actual': 600,\n",
       " 'easi': 601,\n",
       " 'guess': 602,\n",
       " 'train': 603,\n",
       " 'wd': 604,\n",
       " 'shift': 605,\n",
       " 'engin': 606,\n",
       " 'etc': 607,\n",
       " 'sunburn': 608,\n",
       " 'peel': 609,\n",
       " 'blog': 610,\n",
       " 'huge': 611,\n",
       " 'warm': 612,\n",
       " '☆': 613,\n",
       " 'complet': 614,\n",
       " 'triangl': 615,\n",
       " 'northern': 616,\n",
       " 'ireland': 617,\n",
       " 'sight': 618,\n",
       " 'smthng': 619,\n",
       " 'fr': 620,\n",
       " 'hug': 621,\n",
       " 'xoxo': 622,\n",
       " 'uu': 623,\n",
       " 'jaann': 624,\n",
       " 'topnewfollow': 625,\n",
       " 'connect': 626,\n",
       " 'wonder': 627,\n",
       " 'made': 628,\n",
       " 'fluffi': 629,\n",
       " 'insid': 630,\n",
       " 'pirouett': 631,\n",
       " 'moos': 632,\n",
       " 'trip': 633,\n",
       " 'philli': 634,\n",
       " 'decemb': 635,\n",
       " \"i'd\": 636,\n",
       " 'dude': 637,\n",
       " 'x41': 638,\n",
       " 'question': 639,\n",
       " 'flaw': 640,\n",
       " 'pain': 641,\n",
       " 'negat': 642,\n",
       " 'strength': 643,\n",
       " 'went': 644,\n",
       " 'solo': 645,\n",
       " 'move': 646,\n",
       " 'fav': 647,\n",
       " 'nirvana': 648,\n",
       " 'smell': 649,\n",
       " 'teen': 650,\n",
       " 'spirit': 651,\n",
       " 'rip': 652,\n",
       " 'ami': 653,\n",
       " 'winehous': 654,\n",
       " 'coupl': 655,\n",
       " 'tomhiddleston': 656,\n",
       " 'elizabetholsen': 657,\n",
       " 'yaytheylookgreat': 658,\n",
       " 'goodnight': 659,\n",
       " 'vid': 660,\n",
       " 'wake': 661,\n",
       " 'gonna': 662,\n",
       " 'shoot': 663,\n",
       " 'itti': 664,\n",
       " 'bitti': 665,\n",
       " 'teeni': 666,\n",
       " 'bikini': 667,\n",
       " 'much': 668,\n",
       " '4th': 669,\n",
       " 'togeth': 670,\n",
       " 'end': 671,\n",
       " 'xfile': 672,\n",
       " 'content': 673,\n",
       " 'rain': 674,\n",
       " 'fabul': 675,\n",
       " 'fantast': 676,\n",
       " '♡': 677,\n",
       " 'jb': 678,\n",
       " 'forev': 679,\n",
       " 'belieb': 680,\n",
       " 'nighti': 681,\n",
       " 'bug': 682,\n",
       " 'bite': 683,\n",
       " 'bracelet': 684,\n",
       " 'idea': 685,\n",
       " 'foundri': 686,\n",
       " 'game': 687,\n",
       " 'sens': 688,\n",
       " 'pic': 689,\n",
       " 'ef': 690,\n",
       " 'phone': 691,\n",
       " 'woot': 692,\n",
       " 'derek': 693,\n",
       " 'use': 694,\n",
       " 'parkshar': 695,\n",
       " 'gloucestershir': 696,\n",
       " 'aaaahhh': 697,\n",
       " 'man': 698,\n",
       " 'traffic': 699,\n",
       " 'stress': 700,\n",
       " 'reliev': 701,\n",
       " \"how'r\": 702,\n",
       " 'arbeloa': 703,\n",
       " 'turn': 704,\n",
       " '17': 705,\n",
       " 'omg': 706,\n",
       " 'say': 707,\n",
       " 'europ': 708,\n",
       " 'rise': 709,\n",
       " 'find': 710,\n",
       " 'hard': 711,\n",
       " 'believ': 712,\n",
       " 'uncount': 713,\n",
       " 'coz': 714,\n",
       " 'unlimit': 715,\n",
       " 'cours': 716,\n",
       " 'teamposit': 717,\n",
       " 'aldub': 718,\n",
       " '☕': 719,\n",
       " 'rita': 720,\n",
       " 'info': 721,\n",
       " \"we'd\": 722,\n",
       " 'way': 723,\n",
       " 'boy': 724,\n",
       " 'x40': 725,\n",
       " 'true': 726,\n",
       " 'sethi': 727,\n",
       " 'high': 728,\n",
       " 'exe': 729,\n",
       " 'skeem': 730,\n",
       " 'saam': 731,\n",
       " 'peopl': 732,\n",
       " 'polit': 733,\n",
       " 'izzat': 734,\n",
       " 'wese': 735,\n",
       " 'trust': 736,\n",
       " 'khawateen': 737,\n",
       " 'k': 738,\n",
       " 'sath': 739,\n",
       " 'mana': 740,\n",
       " 'kar': 741,\n",
       " 'deya': 742,\n",
       " 'sort': 743,\n",
       " 'smart': 744,\n",
       " 'hair': 745,\n",
       " 'tbh': 746,\n",
       " 'jacob': 747,\n",
       " 'g': 748,\n",
       " 'upgrad': 749,\n",
       " 'tee': 750,\n",
       " 'famili': 751,\n",
       " 'person': 752,\n",
       " 'two': 753,\n",
       " 'convers': 754,\n",
       " 'onlin': 755,\n",
       " 'mclaren': 756,\n",
       " 'fridayfeel': 757,\n",
       " 'tgif': 758,\n",
       " 'squar': 759,\n",
       " 'enix': 760,\n",
       " 'bissmillah': 761,\n",
       " 'ya': 762,\n",
       " 'allah': 763,\n",
       " \"we'r\": 764,\n",
       " 'socent': 765,\n",
       " 'startup': 766,\n",
       " 'drop': 767,\n",
       " 'your': 768,\n",
       " 'arnd': 769,\n",
       " 'town': 770,\n",
       " 'basic': 771,\n",
       " 'piss': 772,\n",
       " 'cup': 773,\n",
       " 'also': 774,\n",
       " 'terribl': 775,\n",
       " 'complic': 776,\n",
       " 'discuss': 777,\n",
       " 'snapchat': 778,\n",
       " 'lynettelow': 779,\n",
       " 'kikmenow': 780,\n",
       " 'snapm': 781,\n",
       " 'hot': 782,\n",
       " 'amazon': 783,\n",
       " 'kikmeguy': 784,\n",
       " 'defin': 785,\n",
       " 'grow': 786,\n",
       " 'sport': 787,\n",
       " 'rt': 788,\n",
       " 'rakyat': 789,\n",
       " 'write': 790,\n",
       " 'sinc': 791,\n",
       " 'mention': 792,\n",
       " 'fli': 793,\n",
       " 'fish': 794,\n",
       " 'promot': 795,\n",
       " 'post': 796,\n",
       " 'cyber': 797,\n",
       " 'ourdaughtersourprid': 798,\n",
       " 'mypapamyprid': 799,\n",
       " 'papa': 800,\n",
       " 'coach': 801,\n",
       " 'posit': 802,\n",
       " 'kha': 803,\n",
       " 'atleast': 804,\n",
       " 'x39': 805,\n",
       " 'mango': 806,\n",
       " \"lassi'\": 807,\n",
       " \"monty'\": 808,\n",
       " 'marvel': 809,\n",
       " 'though': 810,\n",
       " 'suspect': 811,\n",
       " 'meant': 812,\n",
       " '24': 813,\n",
       " 'hr': 814,\n",
       " 'touch': 815,\n",
       " 'kepler': 816,\n",
       " '452b': 817,\n",
       " 'chalna': 818,\n",
       " 'hai': 819,\n",
       " 'thankyou': 820,\n",
       " 'hazel': 821,\n",
       " 'food': 822,\n",
       " 'brooklyn': 823,\n",
       " 'pta': 824,\n",
       " 'awak': 825,\n",
       " 'okayi': 826,\n",
       " 'awww': 827,\n",
       " 'ha': 828,\n",
       " 'doc': 829,\n",
       " 'splendid': 830,\n",
       " 'spam': 831,\n",
       " 'folder': 832,\n",
       " 'amount': 833,\n",
       " 'nigeria': 834,\n",
       " 'claim': 835,\n",
       " 'rted': 836,\n",
       " 'leg': 837,\n",
       " 'hurt': 838,\n",
       " 'bad': 839,\n",
       " 'mine': 840,\n",
       " 'saturday': 841,\n",
       " 'thaaank': 842,\n",
       " 'puhon': 843,\n",
       " 'happinesss': 844,\n",
       " 'tnc': 845,\n",
       " 'prior': 846,\n",
       " 'notif': 847,\n",
       " 'fat': 848,\n",
       " 'co': 849,\n",
       " 'probabl': 850,\n",
       " 'ate': 851,\n",
       " 'yuna': 852,\n",
       " 'tamesid': 853,\n",
       " '´': 854,\n",
       " 'googl': 855,\n",
       " 'account': 856,\n",
       " 'scouser': 857,\n",
       " 'everyth': 858,\n",
       " 'zoe': 859,\n",
       " 'mate': 860,\n",
       " 'liter': 861,\n",
       " \"they'r\": 862,\n",
       " 'samee': 863,\n",
       " 'edgar': 864,\n",
       " 'updat': 865,\n",
       " 'log': 866,\n",
       " 'bring': 867,\n",
       " 'abe': 868,\n",
       " 'meet': 869,\n",
       " 'x38': 870,\n",
       " 'sigh': 871,\n",
       " 'dreamili': 872,\n",
       " 'pout': 873,\n",
       " 'eye': 874,\n",
       " 'quacketyquack': 875,\n",
       " 'funni': 876,\n",
       " 'happen': 877,\n",
       " 'phil': 878,\n",
       " 'em': 879,\n",
       " 'del': 880,\n",
       " 'rodder': 881,\n",
       " 'els': 882,\n",
       " 'play': 883,\n",
       " 'newest': 884,\n",
       " 'gamejam': 885,\n",
       " 'irish': 886,\n",
       " 'literatur': 887,\n",
       " 'inaccess': 888,\n",
       " \"kareena'\": 889,\n",
       " 'fan': 890,\n",
       " 'brain': 891,\n",
       " 'dot': 892,\n",
       " 'braindot': 893,\n",
       " 'fair': 894,\n",
       " 'rush': 895,\n",
       " 'either': 896,\n",
       " 'brandi': 897,\n",
       " '18': 898,\n",
       " 'carniv': 899,\n",
       " 'men': 900,\n",
       " 'put': 901,\n",
       " 'mask': 902,\n",
       " 'xavier': 903,\n",
       " 'forneret': 904,\n",
       " 'jennif': 905,\n",
       " 'site': 906,\n",
       " 'free': 907,\n",
       " '50.000': 908,\n",
       " '8': 909,\n",
       " 'ball': 910,\n",
       " 'pool': 911,\n",
       " 'coin': 912,\n",
       " 'edit': 913,\n",
       " 'trish': 914,\n",
       " '♥': 915,\n",
       " 'grate': 916,\n",
       " 'three': 917,\n",
       " 'comment': 918,\n",
       " 'wakeup': 919,\n",
       " 'besid': 920,\n",
       " 'dirti': 921,\n",
       " 'sex': 922,\n",
       " 'lmaooo': 923,\n",
       " '😤': 924,\n",
       " 'loui': 925,\n",
       " \"he'\": 926,\n",
       " 'throw': 927,\n",
       " 'caus': 928,\n",
       " 'inspir': 929,\n",
       " 'ff': 930,\n",
       " 'twoof': 931,\n",
       " 'gr8': 932,\n",
       " 'wkend': 933,\n",
       " 'kind': 934,\n",
       " 'exhaust': 935,\n",
       " 'word': 936,\n",
       " 'cheltenham': 937,\n",
       " 'area': 938,\n",
       " 'kale': 939,\n",
       " 'crisp': 940,\n",
       " 'ruin': 941,\n",
       " 'x37': 942,\n",
       " 'open': 943,\n",
       " 'worldwid': 944,\n",
       " 'outta': 945,\n",
       " 'sfvbeta': 946,\n",
       " 'vantast': 947,\n",
       " 'xcylin': 948,\n",
       " 'bundl': 949,\n",
       " 'show': 950,\n",
       " 'internet': 951,\n",
       " 'price': 952,\n",
       " 'realisticli': 953,\n",
       " 'pay': 954,\n",
       " 'net': 955,\n",
       " 'educ': 956,\n",
       " 'power': 957,\n",
       " 'weapon': 958,\n",
       " 'nelson': 959,\n",
       " 'mandela': 960,\n",
       " 'recent': 961,\n",
       " 'j': 962,\n",
       " 'chenab': 963,\n",
       " 'flow': 964,\n",
       " 'pakistan': 965,\n",
       " 'incredibleindia': 966,\n",
       " 'teenchoic': 967,\n",
       " 'choiceinternationalartist': 968,\n",
       " 'superjunior': 969,\n",
       " 'caught': 970,\n",
       " 'first': 971,\n",
       " 'salmon': 972,\n",
       " 'super-blend': 973,\n",
       " 'project': 974,\n",
       " 'youth@bipolaruk.org.uk': 975,\n",
       " 'awesom': 976,\n",
       " 'stream': 977,\n",
       " 'alma': 978,\n",
       " 'mater': 979,\n",
       " 'highschoolday': 980,\n",
       " 'clientvisit': 981,\n",
       " 'faith': 982,\n",
       " 'christian': 983,\n",
       " 'school': 984,\n",
       " 'lizaminnelli': 985,\n",
       " 'upcom': 986,\n",
       " 'uk': 987,\n",
       " '😄': 988,\n",
       " 'singl': 989,\n",
       " 'hill': 990,\n",
       " 'everi': 991,\n",
       " 'beat': 992,\n",
       " 'wrong': 993,\n",
       " 'readi': 994,\n",
       " 'natur': 995,\n",
       " 'pefumeri': 996,\n",
       " 'workshop': 997,\n",
       " 'neal': 998,\n",
       " 'yard': 999,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the vocabulary\n",
    "# Unit Test Note - There is no test set here only train/val\n",
    "\n",
    "# Include special tokens \n",
    "# started with pad, end of line and unk tokens\n",
    "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2} \n",
    "\n",
    "# Note that we build vocab using training data\n",
    "for tweet in train_x: \n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    for word in processed_tweet:\n",
    "        if word not in Vocab: \n",
    "            Vocab[word] = len(Vocab)\n",
    "    \n",
    "print(\"Total words in vocab are\",len(Vocab))\n",
    "display(Vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0x8pND8tAVuf"
   },
   "source": [
    "<a name=\"2.3\"></a>\n",
    "## 2.3  Converting a tweet to a tensor\n",
    "\n",
    "Write a function that will convert each tweet to a tensor (a list of unique integer IDs representing the processed tweet).\n",
    "- Note, the returned data type will be a **regular Python `list()`**\n",
    "- For words in the tweet that are not in the vocabulary, set them to the unique ID for the token `__UNK__`.\n",
    "\n",
    "##### Example\n",
    "Input a tweet:\n",
    "```CPP\n",
    "'@happypuppy, is Maria happy?'\n",
    "```\n",
    "\n",
    "The tweet_to_tensor will first conver the tweet into a list of tokens (including only relevant words)\n",
    "```CPP\n",
    "['maria', 'happi']\n",
    "```\n",
    "\n",
    "Then it will convert each word into its unique integer\n",
    "\n",
    "```CPP\n",
    "[2, 56]\n",
    "```\n",
    "- Notice that the word \"maria\" is not in the vocabulary, so it is assigned the unique integer associated with the `__UNK__` token, because it is considered \"unknown.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft1zNGMaAVuf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet - A string containing a tweet\n",
    "        vocab_dict - The words dictionary\n",
    "        unk_token - The special string for unknown tokens\n",
    "        verbose - Print info durign runtime\n",
    "    Output:\n",
    "        tensor_l - A python list with\n",
    "        \n",
    "    '''  \n",
    "    \n",
    "    # Process the tweet into a list of words\n",
    "    # where only important words are kept (stop words removed)\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"List of words from the processed tweet:\")\n",
    "        print(word_l)\n",
    "        \n",
    "    # Initialize the list that will contain the unique integer IDs of each word\n",
    "    tensor_l = []\n",
    "    \n",
    "    # Get the unique integer ID of the __UNK__ token\n",
    "    unk_ID = vocab_dict[unk_token]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
    "        \n",
    "    # for each word in the list:\n",
    "    for word in word_l:\n",
    "        \n",
    "        # Get the unique integer ID.\n",
    "        # If the word doesn't exist in the vocab dictionary,\n",
    "        # use the unique ID for __UNK__ instead.\n",
    "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
    "        \n",
    "        # Append the unique integer ID to the tensor list.\n",
    "        tensor_l.append(word_ID) \n",
    "    \n",
    "    return tensor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ze0Zx_5UjCWU",
    "outputId": "a9427907-b364-4c5f-fed5-bd2502e18bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual tweet is\n",
      " Bro:U wan cut hair anot,ur hair long Liao bo\n",
      "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
      "Bro:LOL Sibei xialan\n",
      "\n",
      "Tensor of tweet:\n",
      " [1065, 136, 479, 2351, 745, 8146, 1123, 745, 53, 2, 2672, 791, 2, 2, 349, 601, 2, 3489, 1017, 597, 4559, 9, 1065, 157, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual tweet is\\n\", val_pos[0])\n",
    "print(\"\\nTensor of tweet:\\n\", tweet_to_tensor(val_pos[0], vocab_dict=Vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwAZZIYYAVuj"
   },
   "source": [
    "<a name=\"2.4\"></a>\n",
    "## 2.4  Creating a batch generator\n",
    "\n",
    "Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. \n",
    "- If instead of training with batches of examples, you were to train a model with one example at a time, it would take a very long time to train the model. \n",
    "- You will now build a data generator that takes in the positive/negative tweets and returns a batch of training examples. It returns the model inputs, the targets (positive or negative labels) and the weight for each target (ex: this allows us to can treat some examples as more important to get right than others, but commonly this will all be 1.0). \n",
    "\n",
    "Once you create the generator, you could include it in a for loop\n",
    "\n",
    "```CPP\n",
    "for batch_inputs, batch_targets, batch_example_weights in data_generator:\n",
    "    ...\n",
    "```\n",
    "\n",
    "You can also get a single batch like this:\n",
    "\n",
    "```CPP\n",
    "batch_inputs, batch_targets, batch_example_weights = next(data_generator)\n",
    "```\n",
    "The generator returns the next batch each time it's called. \n",
    "- This generator returns the data in a format (tensors) that you could directly use in your model.\n",
    "- It returns a triple: the inputs, targets, and loss weights:\n",
    "-- Inputs is a tensor that contains the batch of tweets we put into the model.\n",
    "-- Targets is the corresponding batch of labels that we train to generate.\n",
    "-- Loss weights here are just 1s with same shape as targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fPd9HNT7AVuk"
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle=False):\n",
    "    '''\n",
    "    Input: \n",
    "        data_pos - Set of posstive examples\n",
    "        data_neg - Set of negative examples\n",
    "        batch_size - number of samples per batch. Must be even\n",
    "        loop - True or False\n",
    "        vocab_dict - The words dictionary\n",
    "        shuffle - Shuffle the data order\n",
    "    Yield:\n",
    "        inputs - Subset of positive and negative examples\n",
    "        targets - The corresponding labels for the subset\n",
    "        example_weights - An array specifying the importance of each example\n",
    "        \n",
    "    '''     \n",
    "    # make sure the batch size is an even number\n",
    "    # to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "    \n",
    "    # Number of positive examples in each batch is half of the batch size\n",
    "    # same with number of negative examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "    \n",
    "    # Use pos_index to walk through the data_pos array\n",
    "    # same with neg_index and data_neg\n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "    \n",
    "    len_data_pos = len(data_pos)\n",
    "    len_data_neg = len(data_neg)\n",
    "    \n",
    "    # Get and array with the data indexes\n",
    "    pos_index_lines = list(range(len_data_pos))\n",
    "    neg_index_lines = list(range(len_data_neg))\n",
    "    \n",
    "    # shuffle lines if shuffle is set to True\n",
    "    if shuffle:\n",
    "        rnd.shuffle(pos_index_lines)\n",
    "        rnd.shuffle(neg_index_lines)\n",
    "        \n",
    "    stop = False\n",
    "    \n",
    "    # Loop indefinitely\n",
    "    while not stop:  \n",
    "        \n",
    "        # create a batch with positive and negative examples\n",
    "        batch = []\n",
    "        \n",
    "        # First part: Pack n_to_take positive examples\n",
    "        \n",
    "        # Start from pos_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "                    \n",
    "            # If the positive index goes past the positive dataset lenght,\n",
    "            if pos_index >= len_data_pos: \n",
    "                \n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                \n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                pos_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the positive sample\n",
    "                    rnd.shuffle(pos_index_lines)\n",
    "                    \n",
    "            # get the tweet as pos_index + i\n",
    "            tweet = data_pos[pos_index_lines[pos_index]]\n",
    "            \n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            \n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "            \n",
    "            # Increment pos_index by one\n",
    "            pos_index = pos_index + 1\n",
    "\n",
    "            \n",
    "\n",
    "        # Second part: Pack n_to_take negative examples\n",
    "    \n",
    "        # Using the same batch list, start from neg_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "            \n",
    "            # If the negative index goes past the negative dataset length,\n",
    "            if neg_index >= len_data_neg:\n",
    "                \n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "                    \n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                neg_index = 0\n",
    "                \n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the negative sample\n",
    "                    rnd.shuffle(neg_index_lines)\n",
    "            # get the tweet as pos_index\n",
    "            tweet = data_neg[neg_index_lines[neg_index]]\n",
    "            \n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "            \n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "            \n",
    "            # Increment neg_index by one\n",
    "            neg_index += 1\n",
    "\n",
    "\n",
    "        if stop:\n",
    "            break;\n",
    "\n",
    "        # Update the start index for positive data \n",
    "        # so that it's n_to_take positions after the current pos_index\n",
    "        pos_index += n_to_take\n",
    "        \n",
    "        # Update the start index for negative data \n",
    "        # so that it's n_to_take positions after the current neg_index\n",
    "        neg_index += n_to_take\n",
    "        \n",
    "        # Get the max tweet length (the length of the longest tweet) \n",
    "        # (you will pad all shorter tweets to have this length)\n",
    "        max_len = max([len(t) for t in batch]) \n",
    "        \n",
    "        \n",
    "        # Initialize the input_l, which will \n",
    "        # store the padded versions of the tensors\n",
    "        tensor_pad_l = []\n",
    "        # Pad shorter tweets with zeros\n",
    "        for tensor in batch:\n",
    "\n",
    "            # Get the number of positions to pad for this tensor so that it will be max_len long\n",
    "            n_pad = max_len - len(tensor)\n",
    "            \n",
    "            # Generate a list of zeros, with length n_pad\n",
    "            pad_l = [0]*n_pad\n",
    "            \n",
    "            # concatenate the tensor and the list of padded zeros\n",
    "            tensor_pad = tensor + pad_l\n",
    "            \n",
    "            # append the padded tensor to the list of padded tensors\n",
    "            tensor_pad_l.append(tensor_pad)\n",
    "\n",
    "        # convert the list of padded tensors to a numpy array\n",
    "        # and store this as the model inputs\n",
    "        inputs = np.array(tensor_pad_l)\n",
    "  \n",
    "        # Generate the list of targets for the positive examples (a list of ones)\n",
    "        # The length is the number of positive examples in the batch\n",
    "        target_pos = [1]*n_to_take\n",
    "        \n",
    "        # Generate the list of targets for the negative examples (a list of ones)\n",
    "        # The length is the number of negative examples in the batch\n",
    "        target_neg = [0]*n_to_take\n",
    "        \n",
    "        # Concatenate the positve and negative targets\n",
    "        target_l = target_pos + target_neg\n",
    "        \n",
    "        # Convert the target list into a numpy array\n",
    "        targets = np.array(target_l)\n",
    "\n",
    "        # Example weights: Treat all examples equally importantly.\n",
    "        example_weights = np.ones_like(targets)\n",
    "        \n",
    "\n",
    "\n",
    "### GIVEN CODE ###\n",
    "        # note we use yield and not return\n",
    "        yield inputs, targets, example_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kI9gEdqpjCWd"
   },
   "source": [
    "Now you can use your data generator to create a data generator for the training data, and another data generator for the validation data.\n",
    "\n",
    "We will create a third data generator that does not loop, for testing the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "iIwM4YHtAVum",
    "outputId": "d25aa4ae-bad3-41f5-963c-0a091f8fb108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[2005 4451 3201    9    0    0    0    0    0    0    0]\n",
      " [4954  567 2000 1454 5174 3499  141 3499  130  459    9]\n",
      " [3761  109  136  583 2930 3969    0    0    0    0    0]\n",
      " [ 250 3761    0    0    0    0    0    0    0    0    0]]\n",
      "Targets: [1 1 0 0]\n",
      "Example Weights: [1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Set the random number generator for the shuffle procedure\n",
    "rnd.seed(30) \n",
    "\n",
    "# Create the training data generator\n",
    "def train_generator(batch_size, shuffle = False):\n",
    "    return data_generator(train_pos, train_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def val_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, True, Vocab, shuffle)\n",
    "\n",
    "# Create the validation data generator\n",
    "def test_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, False, Vocab, shuffle)\n",
    "\n",
    "# Get a batch from the train_generator and inspect.\n",
    "inputs, targets, example_weights = next(train_generator(4, shuffle=True))\n",
    "\n",
    "# this will print a list of 4 tensors padded with zeros\n",
    "print(f'Inputs: {inputs}')\n",
    "print(f'Targets: {targets}')\n",
    "print(f'Example Weights: {example_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mcDOyrx9jCWh",
    "outputId": "1adae96d-fb14-4cc6-d39e-7e4d9517c239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs shape is (4, 14)\n",
      "The targets shape is (4,)\n",
      "The example weights shape is (4,)\n",
      "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1; example weights 1\n",
      "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1; example weights 1\n",
      "input tensor: [5738 2901 3761    0    0    0    0    0    0    0    0    0    0    0]; target 0; example weights 1\n",
      "input tensor: [ 858  256 3652 5739  307 4458  567 1230 2767  328 1202 3761    0    0]; target 0; example weights 1\n"
     ]
    }
   ],
   "source": [
    "# Test the train_generator\n",
    "\n",
    "# Create a data generator for training data,\n",
    "# which produces batches of size 4 (for tensors and their respective targets)\n",
    "tmp_data_gen = train_generator(batch_size = 4)\n",
    "\n",
    "# Call the data generator to get one batch and its targets\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = next(tmp_data_gen)\n",
    "\n",
    "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
    "print(f\"The targets shape is {tmp_targets.shape}\")\n",
    "print(f\"The example weights shape is {tmp_example_weights.shape}\")\n",
    "\n",
    "for i,t in enumerate(tmp_inputs):\n",
    "    print(f\"input tensor: {t}; target {tmp_targets[i]}; example weights {tmp_example_weights[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X591GrH_stXq"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "#  Defining classes\n",
    "\n",
    "\n",
    "\n",
    "Your framework will be based on the following `Layer` class from utils.py.\n",
    "\n",
    "```CPP\n",
    "class Layer(object):\n",
    "    \"\"\" Base class for layers.\n",
    "    \"\"\"\n",
    "      \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        # set weights to None\n",
    "        self.weights = None\n",
    "\n",
    "    # The forward propagation should be implemented\n",
    "    # by subclasses of this Layer class\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # This function initializes the weights\n",
    "    # based on the input signature and random key,\n",
    "    # should be implemented by subclasses of this Layer class\n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        pass\n",
    "\n",
    "    # This initializes and returns the weights, do not override.\n",
    "    def init(self, input_signature, random_key):\n",
    "        self.init_weights_and_state(input_signature, random_key)\n",
    "        return self.weights\n",
    " \n",
    "    # __call__ allows an object of this class\n",
    "    # to be called like it's a function.\n",
    "    def __call__(self, x):\n",
    "        # When this layer object is called, \n",
    "        # it calls its forward propagation function\n",
    "        return self.forward(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGE5zZ5mzF9x"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Relu(Layer):\n",
    "    \"\"\"Relu activation function implementation\"\"\"\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input: \n",
    "            - x (a numpy array): the input\n",
    "        Output:\n",
    "            - activation (numpy array): all positive or 0 version of x\n",
    "        '''\n",
    "        \n",
    "        activation = np.maximum(x,0)\n",
    "\n",
    "        \n",
    "        return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XepjDxCQ1G8p"
   },
   "source": [
    "<a name=\"3.2\"></a>\n",
    "##  Dense class \n",
    "\n",
    "\n",
    "\n",
    "Implement the forward function of the Dense class. \n",
    "- The forward function multiplies the input to the layer (`x`) by the weight matrix (`W`)\n",
    "\n",
    "$$\\mathrm{forward}(\\mathbf{x},\\mathbf{W}) = \\mathbf{xW} $$\n",
    "\n",
    "- You can use `numpy.dot` to perform the matrix multiplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJqiv5KnjCWr"
   },
   "outputs": [],
   "source": [
    "# use the fastmath module within trax\n",
    "from trax import fastmath\n",
    "\n",
    "# use the numpy module from trax\n",
    "np = fastmath.numpy\n",
    "\n",
    "# use the fastmath.random module from trax\n",
    "random = fastmath.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "6reTe6asjCWt",
    "outputId": "94480024-f9ec-43d2-f657-f523c9c78504"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random seed generated by random.get_prng\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([0, 1], dtype=uint32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose a matrix with 2 rows and 3 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix generated with a normal distribution with mean 0 and stdev of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 0.957307  , -0.9699291 ,  1.0070664 ],\n",
       "             [ 0.36619022,  0.17294823,  0.29092228]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See how the fastmath.trax.random.normal function works\n",
    "tmp_key = random.get_prng(seed=1)\n",
    "print(\"The random seed generated by random.get_prng\")\n",
    "display(tmp_key)\n",
    "\n",
    "print(\"choose a matrix with 2 rows and 3 columns\")\n",
    "tmp_shape=(2,3)\n",
    "display(tmp_shape)\n",
    "\n",
    "# Generate a weight matrix\n",
    "# Note that you'll get an error if you try to set dtype to tf.float32, where tf is tensorflow\n",
    "# Just avoid setting the dtype and allow it to use the default data type\n",
    "tmp_weight = trax.fastmath.random.normal(key=tmp_key, shape=tmp_shape)\n",
    "\n",
    "print(\"Weight matrix generated with a normal distribution with mean 0 and stdev of 1\")\n",
    "display(tmp_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "783FfWt70660"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Dense(Layer):\n",
    "    \"\"\"\n",
    "    A dense (fully-connected) layer.\n",
    "    \"\"\"\n",
    "\n",
    "    # __init__ is implemented for you\n",
    "    def __init__(self, n_units, init_stdev=0.1):\n",
    "        \n",
    "        # Set the number of units in this layer\n",
    "        self._n_units = n_units\n",
    "        self._init_stdev = 0.1\n",
    "\n",
    "    # Please implement 'forward()'\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        # Matrix multiply x and the weight matrix\n",
    "        dense = np.dot(x, self.weights) \n",
    "        \n",
    "        return dense\n",
    "\n",
    "    # init_weights\n",
    "    def init_weights_and_state(self, input_signature, random_key):\n",
    "        \n",
    "        # The input_signature has a .shape attribute that gives the shape as a tuple\n",
    "        input_shape = input_signature.shape\n",
    "\n",
    "        # Generate the weight matrix from a normal distribution, \n",
    "        # and standard deviation of 'stdev'        \n",
    "        w = self._init_stdev * random.normal(\n",
    "            key = random_key, shape = (input_shape[-1], self._n_units))\n",
    "        \n",
    "        self.weights = w\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "vw-z6n8SAVuy",
    "outputId": "60b4a7ca-f8b6-4dce-9a35-b72eba48db1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights are\n",
      "  [[-0.02837108  0.09368161 -0.10050074  0.14165013  0.105433    0.09108126\n",
      "  -0.04265672  0.0986188  -0.05575325  0.00153249]\n",
      " [-0.20785688  0.0554837   0.09142365  0.05744595  0.07227863  0.01210617\n",
      "  -0.03237354  0.16234994  0.02450038 -0.13809782]\n",
      " [-0.06111238  0.01403724  0.08410042 -0.1094358  -0.10775021 -0.11396459\n",
      "  -0.05933381 -0.01557652 -0.03832145 -0.11144515]]\n",
      "Foward function output is  [[-3.0395498   0.92668015  2.5414746  -2.050473   -1.976939   -2.582209\n",
      "  -1.7952734   0.9442741  -0.8980402  -3.7497485 ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing your Dense layer \n",
    "dense_layer = Dense(n_units=10)  #sets  number of units in dense layer\n",
    "random_key = random.get_prng(seed=0)  # sets random seed\n",
    "z = np.array([[2.0, 7.0, 25.0]]) # input array \n",
    "\n",
    "dense_layer.init(z, random_key)\n",
    "print(\"Weights are\\n \",dense_layer.weights) #Returns randomly generated weights\n",
    "print(\"Foward function output is \", dense_layer(z)) # Returns multiplied values of units and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZEY8vBCgrgy"
   },
   "source": [
    "<a name=\"3.3\"></a>\n",
    "## 3.3  Model\n",
    "\n",
    "Now you will implement a classifier using neural networks. Here is the model architecture you will be implementing. \n",
    "\n",
    "<img src = \"nn.jpg\" style=\"width:400px;height:250px;\"/>\n",
    "\n",
    "For the model implementation, we will use the Trax layers library `tl`.\n",
    "Note that the second character of `tl` is the lowercase of letter `L`, not the number 1. Trax layers are very similar to the ones you implemented above,\n",
    "but in addition to trainable weights also have a non-trainable state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6PptsvwjCW3"
   },
   "source": [
    "- [tl.Embedding](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L113): Layer constructor function for an embedding layer.  \n",
    "    - `tl.Embedding(vocab_size, d_feature)`.\n",
    "    - `vocab_size` is the number of unique words in the given vocabulary.\n",
    "    - `d_feature` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bi4OhkZbjCW6",
    "outputId": "61a46a9c-ef12-42ec-99e7-1ec888937c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding_3_2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_embed = tl.Embedding(vocab_size=3, d_feature=2)\n",
    "display(tmp_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "eSS-_d38jCW-",
    "outputId": "eb19ac1d-7f11-4e5c-e7b4-97544a34f7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean along axis 0 creates a vector whose length equals the vocabulary size\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([2.5, 3.5, 4.5], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean along axis 1 creates a vector whose length equals the number of elements in a word embedding\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 5.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pretend the embedding matrix uses \n",
    "# 2 elements for embedding the meaning of a word\n",
    "# and has a vocabulary size of 3\n",
    "# So it has shape (2,3)\n",
    "tmp_embed = np.array([[1,2,3,],\n",
    "                    [4,5,6]\n",
    "                   ])\n",
    "\n",
    "# take the mean along axis 0\n",
    "print(\"The mean along axis 0 creates a vector whose length equals the vocabulary size\")\n",
    "display(np.mean(tmp_embed,axis=0))\n",
    "\n",
    "print(\"The mean along axis 1 creates a vector whose length equals the number of elements in a word embedding\")\n",
    "display(np.mean(tmp_embed,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wh33Hk8lgrgz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def classifier(vocab_size=len(Vocab), embedding_dim=256, output_dim=2, mode='train'):\n",
    "        \n",
    "    # create embedding layer\n",
    "    embed_layer = tl.Embedding(\n",
    "        vocab_size=vocab_size, # Size of the vocabulary\n",
    "        d_feature=embedding_dim)  # Embedding dimension\n",
    "    \n",
    "    # Create a mean layer, to create an \"average\" word embedding\n",
    "    mean_layer = tl.Mean(axis=1)\n",
    "    \n",
    "    # Create a dense layer, one unit for each output\n",
    "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
    "\n",
    "    \n",
    "    # Create the log softmax layer (no parameters needed)\n",
    "    log_softmax_layer = tl.LogSoftmax()\n",
    "    \n",
    "    # Use tl.Serial to combine all layers\n",
    "    # and create the classifier\n",
    "    # of type trax.layers.combinators.Serial\n",
    "    model = tl.Serial(\n",
    "      embed_layer,  # embedding layer\n",
    "      mean_layer, # mean layer\n",
    "      dense_output_layer, # dense output layer \n",
    "      log_softmax_layer # log softmax layer\n",
    "    )\n",
    "    \n",
    "    # return the model of type\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OwJCu3e9jCXK"
   },
   "outputs": [],
   "source": [
    "tmp_model = classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZsMzvK8YjCXM",
    "outputId": "dbc365af-2a5a-4423-98f1-371d2ee6bba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'trax.layers.combinators.Serial'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  Embedding_9092_256\n",
       "  Mean\n",
       "  Dense_2\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(tmp_model))\n",
    "display(tmp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FaugA_7grg6"
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "#  Training\n",
    "\n",
    "To train a model on a task, Trax defines an abstraction [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) which packages the train data, loss and optimizer (among other things) together into an object.\n",
    "\n",
    "Similarly to evaluate a model, Trax defines an abstraction [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) which packages the eval data and metrics (among other things) into another object.\n",
    "\n",
    "The final piece tying things together is the [`trax.supervised.training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) abstraction that is a very simple and flexible way to put everything together and train the model, all the while evaluating it and saving checkpoints.\n",
    "Using `Loop` will save you a lot of code compared to always writing the training loop by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmR3BhV41Cxs"
   },
   "source": [
    "Notice some available optimizers include:\n",
    "```CPP\n",
    "    adafactor\n",
    "    adam\n",
    "    momentum\n",
    "    rms_prop\n",
    "    sm3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HA01H6K7grg_"
   },
   "source": [
    "<a name=\"4.1\"></a>\n",
    "##   Training the model\n",
    "\n",
    "Now you are going to train your model. \n",
    "\n",
    "Let's define the `TrainTask`, `EvalTask` and `Loop` in preparation to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogMtJgHSoiZj"
   },
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "batch_size = 16\n",
    "rnd.seed(271)\n",
    "\n",
    "train_task = training.TrainTask(\n",
    "    labeled_data=train_generator(batch_size=batch_size, shuffle=True),\n",
    "    loss_layer=tl.CrossEntropyLoss(),\n",
    "    optimizer=trax.optimizers.Adam(0.01),\n",
    "    n_steps_per_checkpoint=10,\n",
    ")\n",
    "\n",
    "eval_task = training.EvalTask(\n",
    "    labeled_data=val_generator(batch_size=batch_size, shuffle=True),\n",
    "    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
    ")\n",
    "\n",
    "model = classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_sw8EGd0Sjk"
   },
   "source": [
    "This defines a model trained using [`tl.CrossEntropyLoss`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss) optimized with the [`trax.optimizers.Adam`](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam) optimizer, all the while tracking the accuracy using [`tl.Accuracy`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy) metric. We also track `tl.CrossEntropyLoss` on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yB78IIUerIVG"
   },
   "source": [
    "Now let's make an output directory and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CNx4LnP9rMsO",
    "outputId": "359fab84-7b89-4eea-b64e-5c681f6952c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gbonco/model/\n"
     ]
    }
   ],
   "source": [
    "output_dir = '~/model/'\n",
    "output_dir_expand = os.path.expanduser(output_dir)\n",
    "print(output_dir_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tolygrj7rpFX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
    "    '''\n",
    "    Input: \n",
    "        classifier - the model you are building\n",
    "        train_task - Training task\n",
    "        eval_task - Evaluation task\n",
    "        n_steps - the evaluation steps\n",
    "        output_dir - folder to save your files\n",
    "    Output:\n",
    "        trainer -  trax trainer\n",
    "    '''\n",
    "    training_loop = training.Loop(\n",
    "                                classifier,  # The learning model\n",
    "                                train_task,  # The training task\n",
    "                                eval_task = eval_task, # The evaluation task\n",
    "                                output_dir = output_dir) # The output directory\n",
    "\n",
    "    training_loop.run(n_steps = n_steps)\n",
    "\n",
    "    # Return the training_loop, since it has the model.\n",
    "    return training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "d-AtiqAYs_rH",
    "outputId": "32fd06b6-9d04-4391-fe3a-689a28734b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      1: train CrossEntropyLoss |  0.60789275\n",
      "Step      1: eval  CrossEntropyLoss |  0.76009548\n",
      "Step      1: eval          Accuracy |  0.56250000\n",
      "Step     10: train CrossEntropyLoss |  0.64948821\n",
      "Step     10: eval  CrossEntropyLoss |  0.45854422\n",
      "Step     10: eval          Accuracy |  0.87500000\n",
      "Step     20: train CrossEntropyLoss |  0.40723333\n",
      "Step     20: eval  CrossEntropyLoss |  0.33322647\n",
      "Step     20: eval          Accuracy |  0.93750000\n",
      "Step     30: train CrossEntropyLoss |  0.25177222\n",
      "Step     30: eval  CrossEntropyLoss |  0.18621588\n",
      "Step     30: eval          Accuracy |  1.00000000\n",
      "Step     40: train CrossEntropyLoss |  0.24520011\n",
      "Step     40: eval  CrossEntropyLoss |  0.44792810\n",
      "Step     40: eval          Accuracy |  0.62500000\n",
      "Step     50: train CrossEntropyLoss |  0.17519739\n",
      "Step     50: eval  CrossEntropyLoss |  0.15775831\n",
      "Step     50: eval          Accuracy |  0.93750000\n",
      "Step     60: train CrossEntropyLoss |  0.11804956\n",
      "Step     60: eval  CrossEntropyLoss |  0.11095993\n",
      "Step     60: eval          Accuracy |  1.00000000\n",
      "Step     70: train CrossEntropyLoss |  0.08826172\n",
      "Step     70: eval  CrossEntropyLoss |  0.15991844\n",
      "Step     70: eval          Accuracy |  0.93750000\n",
      "Step     80: train CrossEntropyLoss |  0.08097079\n",
      "Step     80: eval  CrossEntropyLoss |  0.02399438\n",
      "Step     80: eval          Accuracy |  1.00000000\n",
      "Step     90: train CrossEntropyLoss |  0.07040589\n",
      "Step     90: eval  CrossEntropyLoss |  0.02183634\n",
      "Step     90: eval          Accuracy |  1.00000000\n",
      "Step    100: train CrossEntropyLoss |  0.04796972\n",
      "Step    100: eval  CrossEntropyLoss |  0.00146092\n",
      "Step    100: eval          Accuracy |  1.00000000\n"
     ]
    }
   ],
   "source": [
    "training_loop = train_model(model, train_task, eval_task, 100, output_dir_expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wxn24gyx1Xpd"
   },
   "source": [
    "##### Expected output (Approximately)\n",
    "```CPP\n",
    "Step      1: train CrossEntropyLoss |  0.88939196\n",
    "Step      1: eval  CrossEntropyLoss |  0.68833977\n",
    "Step      1: eval          Accuracy |  0.50000000\n",
    "Step     10: train CrossEntropyLoss |  0.61036736\n",
    "Step     10: eval  CrossEntropyLoss |  0.52182281\n",
    "Step     10: eval          Accuracy |  0.68750000\n",
    "Step     20: train CrossEntropyLoss |  0.34137666\n",
    "Step     20: eval  CrossEntropyLoss |  0.20654774\n",
    "Step     20: eval          Accuracy |  1.00000000\n",
    "Step     30: train CrossEntropyLoss |  0.20208922\n",
    "Step     30: eval  CrossEntropyLoss |  0.21594886\n",
    "Step     30: eval          Accuracy |  0.93750000\n",
    "Step     40: train CrossEntropyLoss |  0.19611198\n",
    "Step     40: eval  CrossEntropyLoss |  0.17582777\n",
    "Step     40: eval          Accuracy |  1.00000000\n",
    "Step     50: train CrossEntropyLoss |  0.11203773\n",
    "Step     50: eval  CrossEntropyLoss |  0.07589275\n",
    "Step     50: eval          Accuracy |  1.00000000\n",
    "Step     60: train CrossEntropyLoss |  0.09375446\n",
    "Step     60: eval  CrossEntropyLoss |  0.09290724\n",
    "Step     60: eval          Accuracy |  1.00000000\n",
    "Step     70: train CrossEntropyLoss |  0.08785903\n",
    "Step     70: eval  CrossEntropyLoss |  0.09610598\n",
    "Step     70: eval          Accuracy |  1.00000000\n",
    "Step     80: train CrossEntropyLoss |  0.08858261\n",
    "Step     80: eval  CrossEntropyLoss |  0.02319432\n",
    "Step     80: eval          Accuracy |  1.00000000\n",
    "Step     90: train CrossEntropyLoss |  0.05699894\n",
    "Step     90: eval  CrossEntropyLoss |  0.01778970\n",
    "Step     90: eval          Accuracy |  1.00000000\n",
    "Step    100: train CrossEntropyLoss |  0.03663783\n",
    "Step    100: eval  CrossEntropyLoss |  0.00210550\n",
    "Step    100: eval          Accuracy |  1.00000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVMcsw2kjCX9"
   },
   "source": [
    "<a name=\"4.2\"></a>\n",
    "##  Practice Making a prediction\n",
    "\n",
    "Now that you have trained a model, you can access it as `training_loop.model` object. We will actually use `training_loop.eval_model`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "WAMgXWY4jCX-",
    "outputId": "7d732b79-6528-49cf-a78a-2f3ee4891681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch is a tuple of length 3 because position 0 contains the tweets, and position 1 contains the targets.\n",
      "The shape of the tweet tensors is (16, 15) (num of examples, length of tweet tensors)\n",
      "The shape of the labels is (16,), which is the batch size.\n",
      "The shape of the example_weights is (16,), which is the same as inputs/targets size.\n"
     ]
    }
   ],
   "source": [
    "# Create a generator object\n",
    "tmp_train_generator = train_generator(16)\n",
    "\n",
    "# get one batch\n",
    "tmp_batch = next(tmp_train_generator)\n",
    "\n",
    "# Position 0 has the model inputs (tweets as tensors)\n",
    "# position 1 has the targets (the actual labels)\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = tmp_batch\n",
    "\n",
    "print(f\"The batch is a tuple of length {len(tmp_batch)} because position 0 contains the tweets, and position 1 contains the targets.\") \n",
    "print(f\"The shape of the tweet tensors is {tmp_inputs.shape} (num of examples, length of tweet tensors)\")\n",
    "print(f\"The shape of the labels is {tmp_targets.shape}, which is the batch size.\")\n",
    "print(f\"The shape of the example_weights is {tmp_example_weights.shape}, which is the same as inputs/targets size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "5XoxD6u5jCX_",
    "outputId": "d857441c-0977-411f-a8de-2037820d8fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction shape is (16, 2), num of tensor_tweets as rows\n",
      "Column 0 is the probability of a negative sentiment (class 0)\n",
      "Column 1 is the probability of a positive sentiment (class 1)\n",
      "\n",
      "View the prediction array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-6.5867472e+00, -1.3794899e-03],\n",
       "             [-4.9628477e+00, -7.0173740e-03],\n",
       "             [-5.6064124e+00, -3.6809444e-03],\n",
       "             [-5.3729963e+00, -4.6510696e-03],\n",
       "             [-4.6580648e+00, -9.5300674e-03],\n",
       "             [-5.2760839e+00, -5.1255226e-03],\n",
       "             [-4.9576702e+00, -7.0540905e-03],\n",
       "             [-3.9602642e+00, -1.9242048e-02],\n",
       "             [-6.3717365e-03, -5.0590839e+00],\n",
       "             [-3.7033916e-02, -3.3143821e+00],\n",
       "             [-1.1131763e-02, -4.5035138e+00],\n",
       "             [-4.4822693e-05, -1.0009674e+01],\n",
       "             [-7.7550411e-03, -4.8632913e+00],\n",
       "             [-4.0259361e-03, -5.5169826e+00],\n",
       "             [-1.7308950e-02, -4.0651746e+00],\n",
       "             [-9.0484619e-03, -4.7096877e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed the tweet tensors into the model to get a prediction\n",
    "tmp_pred = training_loop.eval_model(tmp_inputs)\n",
    "print(f\"The prediction shape is {tmp_pred.shape}, num of tensor_tweets as rows\")\n",
    "print(\"Column 0 is the probability of a negative sentiment (class 0)\")\n",
    "print(\"Column 1 is the probability of a positive sentiment (class 1)\")\n",
    "print()\n",
    "print(\"View the prediction array\")\n",
    "tmp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "6wJHv0TNjCYC",
    "outputId": "0367db61-6e29-44b5-be45-7534600e6931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg log prob -6.5867\tPos log prob -0.0014\t is positive? True\t actual 1\n",
      "Neg log prob -4.9628\tPos log prob -0.0070\t is positive? True\t actual 1\n",
      "Neg log prob -5.6064\tPos log prob -0.0037\t is positive? True\t actual 1\n",
      "Neg log prob -5.3730\tPos log prob -0.0047\t is positive? True\t actual 1\n",
      "Neg log prob -4.6581\tPos log prob -0.0095\t is positive? True\t actual 1\n",
      "Neg log prob -5.2761\tPos log prob -0.0051\t is positive? True\t actual 1\n",
      "Neg log prob -4.9577\tPos log prob -0.0071\t is positive? True\t actual 1\n",
      "Neg log prob -3.9603\tPos log prob -0.0192\t is positive? True\t actual 1\n",
      "Neg log prob -0.0064\tPos log prob -5.0591\t is positive? False\t actual 0\n",
      "Neg log prob -0.0370\tPos log prob -3.3144\t is positive? False\t actual 0\n",
      "Neg log prob -0.0111\tPos log prob -4.5035\t is positive? False\t actual 0\n",
      "Neg log prob -0.0000\tPos log prob -10.0097\t is positive? False\t actual 0\n",
      "Neg log prob -0.0078\tPos log prob -4.8633\t is positive? False\t actual 0\n",
      "Neg log prob -0.0040\tPos log prob -5.5170\t is positive? False\t actual 0\n",
      "Neg log prob -0.0173\tPos log prob -4.0652\t is positive? False\t actual 0\n",
      "Neg log prob -0.0090\tPos log prob -4.7097\t is positive? False\t actual 0\n"
     ]
    }
   ],
   "source": [
    "# turn probabilites into category predictions\n",
    "tmp_is_positive = tmp_pred[:,1] > tmp_pred[:,0]\n",
    "for i, p in enumerate(tmp_is_positive):\n",
    "    print(f\"Neg log prob {tmp_pred[i,0]:.4f}\\tPos log prob {tmp_pred[i,1]:.4f}\\t is positive? {p}\\t actual {tmp_targets[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TywSi02cjCYF"
   },
   "source": [
    "Notice that since you are making a prediction using a training batch, it's more likely that the model's predictions match the actual targets (labels).  \n",
    "- Every prediction that the tweet is positive is also matching the actual target of 1 (positive sentiment).\n",
    "- Similarly, all predictions that the sentiment is not positive matches the actual target of 0 (negative sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6X_0K_EjCYF"
   },
   "source": [
    "One more useful thing to know is how to compare if the prediction is matching the actual target (label).  \n",
    "- The result of calculation `is_positive` is a boolean.\n",
    "- The target is a type trax.fastmath.numpy.int32\n",
    "- If you expect to be doing division, you may prefer to work with decimal numbers with the data type type trax.fastmath.numpy.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "CQgx_ar9jCYG",
    "outputId": "16b00f0d-9f1a-4602-f38e-b58ea3ab52a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of booleans\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([ True,  True,  True,  True,  True,  True,  True,  True,\n",
       "             False, False, False, False, False, False, False, False],            dtype=bool)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of integers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of floats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the array of booleans\n",
    "print(\"Array of booleans\")\n",
    "display(tmp_is_positive)\n",
    "\n",
    "# convert boolean to type int32\n",
    "# True is converted to 1\n",
    "# False is converted to 0\n",
    "tmp_is_positive_int = tmp_is_positive.astype(np.int32)\n",
    "\n",
    "\n",
    "# View the array of integers\n",
    "print(\"Array of integers\")\n",
    "display(tmp_is_positive_int)\n",
    "\n",
    "# convert boolean to type float32\n",
    "tmp_is_positive_float = tmp_is_positive.astype(np.float32)\n",
    "\n",
    "# View the array of floats\n",
    "print(\"Array of floats\")\n",
    "display(tmp_is_positive_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fRRrgOHJgrhI"
   },
   "source": [
    "<a name=\"5\"></a>\n",
    "#   Evaluation  \n",
    "\n",
    "<a name=\"5.1\"></a>\n",
    "##  Computing the accuracy on a batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBqaN5f9grhJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(preds, y, y_weights):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        preds: a tensor of shape (dim_batch, output_dim) \n",
    "        y: a tensor of shape (dim_batch, output_dim) with the true labels\n",
    "        y_weights: a n.ndarray with the a weight for each example\n",
    "    Output: \n",
    "        accuracy: a float between 0-1 \n",
    "        weighted_num_correct (np.float32): Sum of the weighted correct predictions\n",
    "        sum_weights (np.float32): Sum of the weights\n",
    "    \"\"\"\n",
    "    # Create an array of booleans, \n",
    "    # True if the probability of positive sentiment is greater than\n",
    "    # the probability of negative sentiment\n",
    "    # else False\n",
    "    is_pos =  preds[:, 1] > preds[:, 0] \n",
    "\n",
    "    # convert the array of booleans into an array of np.int32\n",
    "    is_pos_int = is_pos.astype(np.int32)\n",
    "    \n",
    "    # compare the array of predictions (as int32) with the target (labels) of type int32\n",
    "    correct = is_pos_int == y \n",
    "\n",
    "    # Count the sum of the weights.\n",
    "    sum_weights = np.sum(y_weights)\n",
    "    \n",
    "    # convert the array of correct predictions (boolean) into an arrayof np.float32\n",
    "    correct_float = correct.astype(np.float32)\n",
    "    \n",
    "    # Multiply each prediction with its corresponding weight.\n",
    "    weighted_correct_float = correct_float * y_weights\n",
    "\n",
    "    # Sum up the weighted correct predictions (of type np.float32), to go in the\n",
    "    # denominator.\n",
    "    weighted_num_correct = np.sum(weighted_correct_float)\n",
    " \n",
    "    # Divide the number of weighted correct predictions by the sum of the\n",
    "    # weights.\n",
    "    accuracy = weighted_num_correct / sum_weights\n",
    "\n",
    "    return accuracy, weighted_num_correct, sum_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2ep7nNejCYP"
   },
   "source": [
    "##### Expected output (Approximately)\n",
    "\n",
    "```\n",
    "Model's prediction accuracy on a single training batch is: 100.0%\n",
    "Weighted number of correct predictions 64.0; weighted number of total observations predicted 64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqle69F1grhM"
   },
   "source": [
    "<a name=\"5.2\"></a>\n",
    "##   Testing your model on Validation Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKoTad4ggrhN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_model(generator, model):\n",
    "    '''\n",
    "    Input: \n",
    "        generator: an iterator instance that provides batches of inputs and targets\n",
    "        model: a model instance \n",
    "    Output: \n",
    "        accuracy: float corresponding to the accuracy\n",
    "    '''\n",
    "    \n",
    "    accuracy = 0.\n",
    "    total_num_correct = 0\n",
    "    total_num_pred = 0\n",
    "    \n",
    "    for batch in generator: \n",
    "        \n",
    "        # Retrieve the inputs from the batch\n",
    "        inputs = batch[0]\n",
    "        \n",
    "        # Retrieve the targets (actual labels) from the batch\n",
    "        targets = batch[1]\n",
    "        \n",
    "        # Retrieve the example weight.\n",
    "        example_weight = batch[2]\n",
    "\n",
    "        # Make predictions using the inputs\n",
    "        pred = model(inputs)\n",
    "        \n",
    "        # Calculate accuracy for the batch by comparing its predictions and targets\n",
    "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight) \n",
    "        \n",
    "        # Update the total number of correct predictions\n",
    "        # by adding the number of correct predictions from this batch\n",
    "        total_num_correct += batch_num_correct\n",
    "        \n",
    "        # Update the total number of predictions \n",
    "        # by adding the number of predictions made for the batch\n",
    "        total_num_pred += batch_num_pred\n",
    "\n",
    "    # Calculate accuracy over all examples\n",
    "    accuracy = total_num_correct / total_num_pred\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1Rm_k21XgrhQ",
    "outputId": "65957ec4-d72b-4363-a5c2-20aa071e9005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of your model on the validation set is 0.9911\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT THIS CELL\n",
    "# testing the accuracy of your model: this takes around 20 seconds\n",
    "model = training_loop.eval_model\n",
    "accuracy = test_model(test_generator(16), model)\n",
    "\n",
    "print(f'The accuracy of your model on the validation set is {accuracy:.4f}', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mct4P9QZgrhT"
   },
   "source": [
    "<a name=\"6\"></a>\n",
    "# Testing with our own input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SUq5cw-xgrhU"
   },
   "outputs": [],
   "source": [
    "# this is used to predict on your own sentnece\n",
    "def predict(sentence):\n",
    "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
    "    \n",
    "    # Batch size 1, add dimension for batch, to work with the model\n",
    "    inputs = inputs[None, :]  \n",
    "    \n",
    "    # predict with the model\n",
    "    preds_probs = model(inputs)\n",
    "    \n",
    "    # Turn probabilities into categories\n",
    "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
    "    \n",
    "    sentiment = \"negative\"\n",
    "    if preds == 1:\n",
    "        sentiment = 'positive'\n",
    "\n",
    "    return preds, sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "3RJntC57grhX",
    "outputId": "01f92c2d-738f-424b-d2b0-6e1f6ade4fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the sentence \n",
      "***\n",
      "\"The movie was almost good!\"\n",
      "***\n",
      "is positive.\n",
      "\n",
      "The sentiment of the sentence \n",
      "***\n",
      "\"the movie was more or less boring\"\n",
      "***\n",
      "is negative.\n"
     ]
    }
   ],
   "source": [
    "# try a positive sentence\n",
    "sentence = \"The movie was almost good!\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")\n",
    "\n",
    "print()\n",
    "# try a negative sentence\n",
    "sentence = \"the movie was more or less boring\"\n",
    "tmp_pred, tmp_sentiment = predict(sentence)\n",
    "print(f\"The sentiment of the sentence \\n***\\n\\\"{sentence}\\\"\\n***\\nis {tmp_sentiment}.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C3_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "NLPC3-1A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
